{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bade83a-07cd-4093-b7c1-3e0589350cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tkinter import messagebox\n",
    "from tkinter import *\n",
    "from tkinter import simpledialog\n",
    "import tkinter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tkinter import ttk\n",
    "from tkinter import filedialog\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88a06bfe-30a9-409e-9408-29e0fc39e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main = Tk()\n",
    "main.title(\"Sentiment Analysis of Customer Product Reviews Using Machine Learning\")\n",
    "main.geometry(\"1350x700+0+0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fadbc6e0-e29b-41e4-8762-985580c4b070",
   "metadata": {},
   "outputs": [],
   "source": [
    "global filename\n",
    "global X, Y\n",
    "global X_train, X_test, y_train, y_test\n",
    "global tfidf_vectorizer\n",
    "accuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8fd23f-7e6d-44d7-9f1f-c2114f7ff4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6153608c-24c2-4728-b545-40bd9679e8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "textdata = []\n",
    "labels = []\n",
    "global classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91641593-9fbc-42df-bd0a-cf7acc0149ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_name = ['Arizona', 'Brazil', 'Brooklyn', 'Chennai', 'Florida', 'India', 'Indonesia',\n",
    "                 'Kerala', 'Kirkwall', 'Pune', 'Sweden', 'United States', 'mexico', 'uk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36ec735d-2223-44c9-8bb0-d87030e05481",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating_name = ['1','5','1'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e9bbb46-2eca-4850-9f69-1c6cd6570d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanPost(doc):\n",
    "    tokens = doc.split()\n",
    "    table = str.maketrans('', '', punctuation)\n",
    "    tokens = [w.translate(table) for w in tokens]\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    tokens = [w for w in tokens if not w in stop_words]\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    tokens = ' '.join(tokens)\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "386cccdc-5133-427e-afe6-3fffad63c053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Addfile():    \n",
    "    global filename\n",
    "    text.delete('1.0', END)\n",
    "    le = LabelEncoder()\n",
    "    filename = filedialog.askopenfilename(initialdir=\"Desktop\")\n",
    "    textdata.clear()\n",
    "    labels.clear()\n",
    "    dataset = pd.read_csv(filename)\n",
    "    print(np.unique(dataset['Review Text']))\n",
    "    dataset['location'] = pd.Series(le.fit_transform(dataset['location'].astype(str)))\n",
    "    print(np.unique(dataset['location']))\n",
    "    for i in range(len(dataset)):\n",
    "        msg = dataset._get_value(i, 'Review Text')\n",
    "        label = dataset._get_value(i, 'location')\n",
    "        msg = str(msg)\n",
    "        msg = msg.strip().lower()\n",
    "        labels.append(label)\n",
    "        clean = cleanPost(msg)\n",
    "        textdata.append(clean)\n",
    "        text.insert(END,clean+\"\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93d609f-7cd7-4b01-b094-4eae9ac389b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor():\n",
    "    text.delete('1.0', END)\n",
    "    global X, Y\n",
    "    global tfidf_vectorizer\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    stopwords=stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=stopwords, use_idf=True, ngram_range=(1,2),smooth_idf=False, norm=None, decode_error='replace')\n",
    "    tfidf = tfidf_vectorizer.fit_transform(textdata).toarray()        \n",
    "    df = pd.DataFrame(tfidf, columns=tfidf_vectorizer.get_feature_names())\n",
    "    text.insert(END,str(df))\n",
    "    print(df.shape)\n",
    "    df = df.values\n",
    "    X = df[:, 0:df.shape[1]]\n",
    "    Y = np.asarray(labels)\n",
    "    indices = np.arange(X.shape[0])\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "    print(X)\n",
    "    print(Y)\n",
    "    print(Y.shape)\n",
    "    print(X.shape)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)\n",
    "    text.insert(END,\"\\n\\nTotal Reviews found in dataset : \"+str(len(X))+\"\\n\")\n",
    "    text.insert(END,\"Total Reviews used to train machine learning algorithms : \"+str(len(X_train))+\"\\n\")\n",
    "    text.insert(END,\"Total Reviews used to test machine learning algorithms  : \"+str(len(X_test))+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2bd459a-5ed9-49cc-b4e5-b86ca7a3e57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_algorithm():\n",
    "    global X, Y\n",
    "    global tfidf_vectorizer\n",
    "    global classifier\n",
    "    global X_train, X_test, y_train, y_test\n",
    "    global accuracy\n",
    "    accuracy.clear()\n",
    "    text.delete('1.0', END) \n",
    "    cls = SVC()\n",
    "    cls.fit(X, Y)\n",
    "    predict = cls.predict(X_test) \n",
    "    a = accuracy_score(y_test,predict)*100\n",
    "    accuracy.append(a)\n",
    "    text.insert(END,\"SVM Accuracy : \"+str(a)+\"\\n\\n\")\n",
    "    classifier = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3059f55-e267-4605-bc62-be1eead1225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes():\n",
    "    cls = GaussianNB()\n",
    "    cls.fit(X_train, y_train)\n",
    "    predict = cls.predict(X_test) \n",
    "    a = accuracy_score(y_test,predict)*100\n",
    "    accuracy.append(a)\n",
    "    text.insert(END,\"Naive Bayes Accuracy : \"+str(a)+\"\\n\\n\")\n",
    "    classifier = cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7474351-1bfc-4493-87db-72b119bbecab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decesion_tree():\n",
    "    cls = DecisionTreeClassifier()\n",
    "    cls.fit(X, Y)\n",
    "    predict = cls.predict(X_test) \n",
    "    a = accuracy_score(y_test,predict)*100\n",
    "    accuracy.append(a)\n",
    "    text.insert(END,\"Decision Tree Accuracy : \"+str(a)+\"\\n\\n\")\n",
    "    classifier = cls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "461191aa-1a6c-48f6-8559-bf237a993198",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_graph():\n",
    "    height = accuracy\n",
    "    bars = ('Naive Bayes','SVM','Decision Tree')\n",
    "    y_pos = np.arange(len(bars))\n",
    "    plt.bar(y_pos, height)\n",
    "    plt.xticks(y_pos, bars)\n",
    "    plt.title('Accuracy Comparison Graph')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85a33cbe-6c4b-4b4d-b7c0-1b671be54ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    global tfidf_vectorizer\n",
    "    global classifier\n",
    "    testfile = filedialog.askopenfilename(initialdir=\"Dataset\")\n",
    "    testData = pd.read_csv(testfile)\n",
    "    text.delete('1.0', END)\n",
    "    testData = testData.values\n",
    "    print(testData)\n",
    "    for i in range(len(testData)):\n",
    "        msg = testData[i]\n",
    "        msg1 = testData[i]\n",
    "        msg = msg[0]\n",
    "        msg2 = \"Review : \"\n",
    "        print(msg)\n",
    "        review = msg.lower()\n",
    "        review = review.strip().lower()\n",
    "        review = cleanPost(review)\n",
    "        testReview = tfidf_vectorizer.transform([review]).toarray()\n",
    "        predict = classifier.predict(testReview)[0]\n",
    "        print(predict)\n",
    "        text.insert(END,msg2 + str(msg1)+Rating_name[predict]+\"\\nPositive: \"+Rating_name[predict]+\"\\nNegative: 0\\n\\n\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b47e016a-adfb-4a3a-9dfd-3ff269aef5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ('times', 20, 'bold')\n",
    "bg_color=\"#E3CF57\" \n",
    "title=Label(text=\"Sentiment Analysis of Customer Product Reviews using Machine Learning\",bd=12,relief=GROOVE,bg= bg_color,fg=\"purple\",font=(\"times new roman\",20,\"bold\"),pady=20).pack(fill=X)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f87b60ee-1e97-4d8e-94ab-bb7d4c139eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "font1 = ('times', 13, 'bold')\n",
    "ff = ('times', 12, 'bold')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "80f08d11-96b8-4921-9d8c-8f1f035f13e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_1 = Button(text=\"Upload Amazon Reviews Dataset\",bd=7,command = Addfile)\n",
    "btn_1.place(x=20,y=150)\n",
    "btn_1.config(font=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07c027df-e894-4f44-9d7d-751b7adb3896",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_2 = Button(text=\"Preprocess Dataset\",bd=7,command =preprocessor)\n",
    "btn_2.place(x=20,y=200)\n",
    "btn_2.config(font=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d4b8f33-ab2e-4674-9bc1-f40be912e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_3 = Button(text=\"Run SVM Algorithm\",bd=7,command = SVM_algorithm)\n",
    "btn_3.place(x=20,y=250)\n",
    "btn_3.config(font=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ce81c63d-52da-4f5a-9161-77a6966011f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_4 = Button(text=\"Run Naive Bayes Algorithm\",bd=7 ,command = Naive_Bayes)\n",
    "btn_4.place(x=20,y=300)\n",
    "btn_4.config(font=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d7628ce7-79e9-463e-9046-38eed54d9ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_5 = Button(text=\"Run Deceision Tree Algorithm\",bd=7,command = decesion_tree)\n",
    "btn_5.place(x=20,y=350)\n",
    "btn_5.config(font=ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e8cd41ec-cc99-4a17-bfd0-5c2b0f42a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_6 = Button(text=\"Detect Sentiment from Test Reviews\",bd=7,command= predict)\n",
    "btn_6.place(x=20,y=400)\n",
    "btn_6.config(font=ff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bfe2a529-fc26-4441-8657-4251c3d03f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "btn_7 = Button(text=\"Accuracy Graph\",bd=7,command = accuracy_graph)\n",
    "btn_7.place(x=20,y=450)\n",
    "btn_7.config(font=ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12011ca6-7cad-45b4-a419-abb32cefbbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "font1 = ('times', 12, 'bold')\n",
    "text=Text(main,height=30,width=120)\n",
    "scroll=Scrollbar(text)\n",
    "text.configure(yscrollcommand=scroll.set)\n",
    "text.place(x=430,y=120,width=1100,height=550)\n",
    "text.config(font=font1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfadf87c-3626-42f0-989e-b243dfe15e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.config(bg='#C0FF3E')\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee8231-ce37-481c-bc4d-72609747be68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7773b70c-6603-410b-9759-0741b02a72e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a96348-6fe1-4224-ab3a-9fda976c85d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
